% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/BLP.R
\name{blp_estimation}
\alias{blp_estimation}
\title{BLP Estimation}
\usage{
blp_estimation(Y, D, cates, pscore, mu, mu0, mu1, scores)
}
\arguments{
\item{Y}{Observed outcomes.}

\item{D}{Treatment indicator.}

\item{cates}{Estimated CATEs. Must be estimated with different observations than those in \code{Y} and \code{D}.}

\item{pscore}{Propensity scores. If unknown, must be estimated using different observations than those in \code{Y} and \code{D}.}

\item{mu}{Estimated regression function. Must be estimated with different observations than those in \code{Y} and \code{D}.}

\item{mu0}{Estimated regression function for control units. Must be estimated with different observations than those in \code{Y} and \code{D}.}

\item{mu1}{Estimated regression function for treated units. Must be estimated with different observations than those in \code{Y} and \code{D}.}

\item{scores}{Estimated doubly-robust scores. Must be estimated via K-fold cross-fitting with the same observations as in \code{Y} and \code{D}.}
}
\value{
A list of fitted models as \code{\link[estimatr]{lm_robust}} objects.
}
\description{
Estimates the best linear predictor (BLP) of the actual CATEs using the estimated CATEs.
}
\details{
To estimate the BLP of the actual CATEs using the estimated CATEs, the user must provide observations on the outcomes and the treatment status of units in 
the validation sample, as well as their estimated cates and nuisance functions. Be careful, as these estimates must be obtained using only observations from the training sample (see the example section below).
Additionally, the user must provide doubly-robust scores estimated in the validation sample using K-fold cross fitting.\cr

The BLP is estimated using three different strategies, all involving fitting suitable linear models. For each of these strategis, different model specifications are considered that differ in additional and
optional covariates that can be included in the regressions to reduce the estimation variance. Check the online \href{https://riccardo-df.github.io/evaluCATE/articles/evalue-cates-short-tutorial.html}{short tutorial}
and \href{https://riccardo-df.github.io/evaluCATE/articles/denoising.html}{denoising vignette} for details.\cr

Standard errors are estimated using the Eicker-Huber-White estimator.
}
\examples{
\donttest{## Generate data.
set.seed(1986)

n <- 1000
k <- 2

X <- matrix(rnorm(n * k), ncol = k)
colnames(X) <- paste0("x", seq_len(k))
D <- rbinom(n, size = 1, prob = 0.5)
mu0 <- 0.5 * X[, 1]
mu1 <- 0.5 * X[, 1] + X[, 2]
Y <- mu0 + D * (mu1 - mu0) + rnorm(n)

## Sample split.
train_idx <- sample(c(TRUE, FALSE), length(Y), replace = TRUE)

X_tr <- X[train_idx, ]
X_val <- X[!train_idx, ]

D_tr <- D[train_idx]
D_val <- D[!train_idx]

Y_tr <- Y[train_idx]
Y_val <- Y[!train_idx]

## CATEs and nuisance functions estimation.
## We use only the training sample for estimation.
## We predict on the validation sample.
library(grf)

cates_forest <- causal_forest(X_tr, Y_tr, D_tr) 
mu_forest <- regression_forest(X_tr, Y_tr)
mu0_forest <- regression_forest(X_tr[D_tr == 0, ], Y_tr[D_tr == 0])
mu1_forest <- regression_forest(X_tr[D_tr == 1, ], Y_tr[D_tr == 1])

cates_val <- predict(cates_forest, X_val)$predictions 
mu_val <- predict(mu_forest, X_val)$predictions
mu0_val <- predict(mu0_forest, X_val)$predictions
mu1_val <- predict(mu1_forest, X_val)$predictions

## AIPW scores estimation.
## Cross-fitting on the validation sample.
library(aggTrees)
scores_val <- dr_scores(Y_val, D_val, X_val)

## BLP estimation. 
pscore_val <- rep(0.5, length(Y_val)) # We know true pscores.
blp_results <- blp_estimation(Y_val, D_val, cates_val, 
                              pscore_val, mu_val, mu0_val, mu1_val, 
                              scores_val)}

}
\seealso{
\code{\link{gates_estimation}}, \code{\link{toc_estimation}}, \code{\link{rate_estimation}}
}
\author{
Riccardo Di Francesco
}
